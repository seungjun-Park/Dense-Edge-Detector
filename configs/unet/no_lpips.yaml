module:
  target: models.unet.UNet
  params:
    lr: 2e-5
    log_interval: 50
    loss_config:
      target: losses.l1lpips.L1LPIPS
      params:
        lpips_weight: 0.0
        l1_weight: 1.0
        l1_balance_weight: 1.5
        granularity_weight: 0.0
        lpieps_eight: 0.0
        threshold: 0.3

    in_channels: 3
    model_channels: 64
    out_channels: 1
    num_res_blocks: 2
    channels_mult: [ 1, 2, 4 ]
    drop_prob: 0.2
    use_checkpoint: True

data:
  target: datasets.util.DataModuleFromConfig
  params:
    num_workers: 4
    batch_size: 2
    wrap: True
    train:
      target: datasets.anime.AnimeDataset
      params:
        root: '/local_datasets/anime'
        # root: 'D:/datasets/anime'
        train: True
        size: [512, 512]
        scale: [ 0.75, 1.0 ]
        granularity_version: 'vgg'

    validation:
      target: datasets.anime.AnimeDataset
      params:
        root: '/local_datasets/anime'
        # root: 'D:/datasets/anime'
        train: False
        size: [512, 512]
        scale: [ 0.75, 1.0 ]
        granularity_version: 'vgg'

logger:
  target: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
  params:
    save_dir: './logs'
    name: 'unet'
    version: 'no_lpips'


checkpoints:
  latest_checkpoints:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/unet/no_lpips'
      filename: 'last'
      monitor: 'step'
      mode: 'max'
      save_top_k: 1

  best_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: './checkpoints/unet/no_lpips'
      filename: 'best'
      monitor: 'valid/total_loss'
      mode: 'min'
      save_top_k: 1

trainer:
  accelerator: 'gpu'
  max_epochs: 100
  accumulate_grad_batches: 2